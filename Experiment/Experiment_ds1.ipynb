{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqmNEUdcGKvv",
        "outputId": "b761f932-71ef-4699-f30b-f0449df36919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeGCETjEGb9p",
        "outputId": "9e3dd070-9e09-41bf-dca2-239a11f407e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exp3.ipynb  test_dataset  train_dataset  val_dataset\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#os.chdir(\"/content/drive/MyDrive/DL_Project/Experiment3\")\n",
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "dataset = 'https://drive.google.com/uc?id=18Q_YSek5Zgs1kXl68MPQJIvyo4KepJvj&export=download'\n",
        "output='./new.zip'\n",
        "gdown.download(dataset, output, quiet=False)"
      ],
      "metadata": {
        "id": "QjugVTCkwJwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('./new.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "metadata": {
        "id": "B8UBT8pFwY_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SCRIPT3 FIND AND REMOVE CORRUPTED IMAGES\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "categ = ['train_dataset','test_dataset','val_dataset']\n",
        "dataset = '/content/drive/MyDrive/DL_Project/Experiment3'\n",
        "bad_file_list=[]\n",
        "bad_count=0\n",
        "\n",
        "for cat in categ:\n",
        "  img_path = os.path.join(dataset, cat)\n",
        "  for foldername in os.listdir(img_path):\n",
        "    sign_path = os.path.join(img_path, foldername)\n",
        "    print(sign_path)\n",
        "    for sign in listdir(sign_path):\n",
        "      if sign.endswith('.jpg'):\n",
        "        try:\n",
        "          Image.open(os.path.join(sign_path, sign)).load() # open the image file\n",
        "           # verify that it is, in fact an image\n",
        "        except:\n",
        "          bad_file_list.append(os.path.join(sign_path, sign))\n",
        "          bad_count +=1\n",
        "print(bad_file_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY9DjHZaWNbB",
        "outputId": "f1470813-665c-437a-ef8c-bc23c34a4a2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DL_Project/Experiment3/train_dataset/2\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/train_dataset/3\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/train_dataset/1\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/test_dataset/2\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/test_dataset/1\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/test_dataset/3\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/val_dataset/3\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/val_dataset/2\n",
            "/content/drive/MyDrive/DL_Project/Experiment3/val_dataset/1\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/drive/MyDrive/DL_Project/Experiment3/val_dataset/2/0c416a95-6e96-4e8c-bab3-56b682feafe9.jpg.jpg.jpg'"
      ],
      "metadata": {
        "id": "rpeh7dOWW9Ol"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fTEvLqmqaPpf"
      },
      "outputs": [],
      "source": [
        "#SCRIPT4  CREATE DICTIONARY WITH CANDIDATE HYPERPARAMS\n",
        "\n",
        "models = []\n",
        "one = {\"kernel_num\": 64, \"kernel_size\": 3, \"fc_size\": 1024, \"conv_layer\":4}\n",
        "two = {\"kernel_num\": 64, \"kernel_size\": 3, \"fc_size\": 1024, \"conv_layer\":3}\n",
        "three = {\"kernel_num\": 32, \"kernel_size\": 3, \"fc_size\": 768, \"conv_layer\":3}\n",
        "four = {\"kernel_num\": 32, \"kernel_size\": 3, \"fc_size\": 1024, \"conv_layer\":4}\n",
        "five = {\"kernel_num\": 64, \"kernel_size\": 4, \"fc_size\": 512, \"conv_layer\":4}\n",
        "six = {\"kernel_num\": 32, \"kernel_size\": 4, \"fc_size\": 768, \"conv_layer\":2}\n",
        "\n",
        "models.append(one)\n",
        "models.append(two)\n",
        "models.append(three)\n",
        "models.append(four)\n",
        "models.append(five)\n",
        "models.append(six)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9-F3J6uEaZxh"
      },
      "outputs": [],
      "source": [
        "#SCRIPT5 DEFINE SAVE/LOAD STATE\n",
        "import os\n",
        "import pickle\n",
        "def save_state(mod,epochs,model_type):\n",
        "    with open('state.state', 'wb') as cfg:\n",
        "      pickle.dump(mod, cfg)\n",
        "      pickle.dump(epochs,cfg)\n",
        "      pickle.dump(model_type,cfg)\n",
        "\n",
        "def load_state():\n",
        "    with open('state.state','rb') as cffile: \n",
        "      model2 = pickle.load(cffile)\n",
        "      epochs2 = pickle.load(cffile)\n",
        "      model_type = pickle.load(cffile)\n",
        "    return model2, epochs2, model_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tO3MQBhAagTd"
      },
      "outputs": [],
      "source": [
        "#create model function\n",
        "from tensorflow.keras.layers import Input, Conv2D , Dropout, MaxPool2D, Flatten, Dense \n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "def create_model(ker_num,ker_size,fc_size,conv_layer_num):\n",
        "  \n",
        "  input = Input(shape =(150,150,3))\n",
        "  weight_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.0, seed=1234)\n",
        "  bias_initializer=tf.keras.initializers.Zeros()\n",
        "\n",
        "  if conv_layer_num == 2:\n",
        "    x = Conv2D (filters =ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(input)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    x = Conv2D (filters =2*ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  elif conv_layer_num == 3:\n",
        "\n",
        "    x = Conv2D (filters =ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(input)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    x = Conv2D (filters =2*ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    x = Conv2D (filters =4*ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  else:\n",
        "    x = Conv2D (filters =ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(input)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    x = Conv2D (filters =2*ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    x = Conv2D (filters =4*ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    x = Conv2D (filters =8*ker_num, kernel_size =ker_size, padding ='same', activation='relu',kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(units = fc_size, activation ='relu', kernel_initializer=weight_initializer,kernel_regularizer=l2(0.00005),bias_initializer=bias_initializer)(x)\n",
        "  output = Dense(units = 3, activation ='softmax')(x)\n",
        "\n",
        "  model = Model (inputs=input, outputs =output)\n",
        "  model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQ42gKI6aob8"
      },
      "outputs": [],
      "source": [
        "#FUNCTION FOR GETTING DATASETS\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def get_datasets():\n",
        "#appply data augmentation on TRAIN DATA ONLY!!\n",
        "  train_datagen = ImageDataGenerator( rescale = 1.0/255.,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True) \n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    directory=r\"./train_dataset/\",\n",
        "    target_size=(150, 150),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "\n",
        "  val_datagen = ImageDataGenerator( rescale = 1.0/255.)\n",
        "\n",
        "  val_generator = val_datagen.flow_from_directory(\n",
        "    directory=r\"./val_dataset/\",\n",
        "    target_size=(150, 150),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "\n",
        "  test_datagen = ImageDataGenerator( rescale = 1.0/255.)\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "    directory=r\"./test_dataset/\",\n",
        "    target_size=(150, 150),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "  \n",
        "  return train_generator, val_generator, test_generator\n",
        "  #one, two, three = get_datasets()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f93Fh1Taaxxi"
      },
      "outputs": [],
      "source": [
        "#CALLBACK\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from timeit import default_timer as timer\n",
        "stop_flag = False\n",
        "\n",
        "\n",
        "class newcb(keras.callbacks.Callback):\n",
        "  def __init__(self, start):\n",
        "    self.start = start\n",
        "    print(self.start,'\\nINIT TIME\\n')\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "      end = timer()\n",
        "      print('\\nCALLBACK time ', end,'\\n')\n",
        "      if end-self.start > 80000:\n",
        "        print('\\nTERMINATING TRAIN DUE TO EXCEEDING 5 HOURS\\n')\n",
        "        print(current_arch,' SAVING ARCH\\n')\n",
        "        save_state(self.model,epoch,current_arch)\n",
        "        self.model.stop_training = True\n",
        "        global stop_flag\n",
        "        stop_flag = True\n",
        "        print(stop_flag,' STOP FLAG CALLBACK\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SCRIPT 9 CREATE CLASS WEIGHTS\n",
        "import os\n",
        "\n",
        "def compute_weigths():\n",
        "  size_per_class = []\n",
        "  a = os.listdir('./train_dataset/')\n",
        "  b = [int(w) for w in a]\n",
        "  b.sort()\n",
        "  print(b)\n",
        "\n",
        "  for i in b:\n",
        "    temp = os.listdir('./train_dataset/'+ str(i))\n",
        "    size_per_class.append(len(temp))\n",
        "\n",
        "  #print(size_per_class)\n",
        "  total = sum(size_per_class)\n",
        "  #print(total)\n",
        "\n",
        "  class_weights = {0: 1, 1: 1, 2: 1}\n",
        "  #print(class_weights)\n",
        "  for i in range(len(size_per_class)):\n",
        "    weigth = (total)/(3*size_per_class[i])\n",
        "    class_weights[i] = weigth\n",
        "\n",
        "  #print(class_weights)\n",
        "  return class_weights \n",
        "\n",
        "weights_per_class = compute_weigths()\n",
        "print(weights_per_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyZG2O3Utecd",
        "outputId": "843cb398-d65f-4ede-bf14-c54f84b9a1ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n",
            "{0: 0.4398543842988287, 1: 2.790160642570281, 2: 2.716520039100684}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cry57Q_ha57D",
        "outputId": "1b4e2930-5b0a-4c18-b957-5dba44969ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CREATING MODEL\n",
            "\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 75, 75, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 38, 38, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 38, 38, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 19, 19, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 19, 19, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 10, 10, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 51200)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 51200)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              52429824  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,983,875\n",
            "Trainable params: 53,983,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Found 2779 images belonging to 3 classes.\n",
            "Found 449 images belonging to 3 classes.\n",
            "Found 450 images belonging to 3 classes.\n",
            "{'1': 0, '2': 1, '3': 2}\n",
            "{'1': 0, '2': 1, '3': 2}\n",
            "{'1': 0, '2': 1, '3': 2}\n",
            "226.240792722 \n",
            "INIT TIME\n",
            "\n",
            "RUNNING MODEL  0\n",
            "Epoch 1/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3626228.7500 - accuracy: 0.3472\n",
            "CALLBACK time  1133.054436352 \n",
            "\n",
            "174/174 [==============================] - 894s 5s/step - loss: 3626228.7500 - accuracy: 0.3472 - val_loss: 1278044.8750 - val_accuracy: 0.3630\n",
            "Epoch 2/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 1115892.2500 - accuracy: 0.3451\n",
            "CALLBACK time  1205.470595846 \n",
            "\n",
            "174/174 [==============================] - 44s 252ms/step - loss: 1115892.2500 - accuracy: 0.3451 - val_loss: 424615.5312 - val_accuracy: 0.3497\n",
            "Epoch 3/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 576234.8125 - accuracy: 0.3580\n",
            "CALLBACK time  1286.739110555 \n",
            "\n",
            "174/174 [==============================] - 43s 247ms/step - loss: 576234.8125 - accuracy: 0.3580 - val_loss: 391472.2188 - val_accuracy: 0.3608\n",
            "Epoch 4/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 326325.7812 - accuracy: 0.3512\n",
            "CALLBACK time  1328.846217375 \n",
            "\n",
            "174/174 [==============================] - 42s 242ms/step - loss: 326325.7812 - accuracy: 0.3512 - val_loss: 153189.8281 - val_accuracy: 0.3697\n",
            "Epoch 5/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 217594.5469 - accuracy: 0.3656\n",
            "CALLBACK time  1410.779608231 \n",
            "\n",
            "174/174 [==============================] - 42s 242ms/step - loss: 217594.5469 - accuracy: 0.3656 - val_loss: 114198.8125 - val_accuracy: 0.3653\n",
            "Epoch 6/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 153801.8750 - accuracy: 0.3393\n",
            "CALLBACK time  1492.148913475 \n",
            "\n",
            "174/174 [==============================] - 42s 238ms/step - loss: 153801.8750 - accuracy: 0.3393 - val_loss: 83550.3438 - val_accuracy: 0.3519\n",
            "Epoch 7/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 108383.8047 - accuracy: 0.3656\n",
            "CALLBACK time  1533.976588733 \n",
            "\n",
            "174/174 [==============================] - 42s 239ms/step - loss: 108383.8047 - accuracy: 0.3656 - val_loss: 66428.2500 - val_accuracy: 0.3586\n",
            "Epoch 8/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 77363.7344 - accuracy: 0.3480\n",
            "CALLBACK time  1615.982805772 \n",
            "\n",
            "174/174 [==============================] - 42s 241ms/step - loss: 77363.7344 - accuracy: 0.3480 - val_loss: 34294.6250 - val_accuracy: 0.3408\n",
            "Epoch 9/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 50318.4961 - accuracy: 0.3537\n",
            "CALLBACK time  1699.275515576 \n",
            "\n",
            "174/174 [==============================] - 43s 249ms/step - loss: 50318.4961 - accuracy: 0.3537 - val_loss: 20414.7773 - val_accuracy: 0.3519\n",
            "Epoch 10/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 32206.7070 - accuracy: 0.3498\n",
            "CALLBACK time  1780.0014542 \n",
            "\n",
            "174/174 [==============================] - 42s 242ms/step - loss: 32206.7070 - accuracy: 0.3498 - val_loss: 10864.7451 - val_accuracy: 0.3096\n",
            "Epoch 11/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 23082.5508 - accuracy: 0.3642\n",
            "CALLBACK time  1861.389183208 \n",
            "\n",
            "174/174 [==============================] - 42s 239ms/step - loss: 23082.5508 - accuracy: 0.3642 - val_loss: 8823.1699 - val_accuracy: 0.3341\n",
            "Epoch 12/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 15390.1445 - accuracy: 0.3372\n",
            "CALLBACK time  1902.506462145 \n",
            "\n",
            "174/174 [==============================] - 41s 236ms/step - loss: 15390.1445 - accuracy: 0.3372 - val_loss: 5505.7974 - val_accuracy: 0.3274\n",
            "Epoch 13/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 11653.1709 - accuracy: 0.3447\n",
            "CALLBACK time  1984.767903396 \n",
            "\n",
            "174/174 [==============================] - 41s 238ms/step - loss: 11653.1709 - accuracy: 0.3447 - val_loss: 4665.5420 - val_accuracy: 0.3252\n",
            "Epoch 14/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 8369.3340 - accuracy: 0.3141\n",
            "CALLBACK time  2026.953678821 \n",
            "\n",
            "174/174 [==============================] - 42s 243ms/step - loss: 8369.3340 - accuracy: 0.3141 - val_loss: 3314.1138 - val_accuracy: 0.3586\n",
            "Epoch 15/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 7146.6514 - accuracy: 0.3239\n",
            "CALLBACK time  2068.551875303 \n",
            "\n",
            "174/174 [==============================] - 42s 238ms/step - loss: 7146.6514 - accuracy: 0.3239 - val_loss: 3073.5203 - val_accuracy: 0.3497\n",
            "Epoch 16/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 5293.0269 - accuracy: 0.3257\n",
            "CALLBACK time  2109.746774189 \n",
            "\n",
            "174/174 [==============================] - 41s 237ms/step - loss: 5293.0269 - accuracy: 0.3257 - val_loss: 2740.0891 - val_accuracy: 0.3808\n",
            "Epoch 17/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 4740.6123 - accuracy: 0.3332\n",
            "CALLBACK time  2192.576017225 \n",
            "\n",
            "174/174 [==============================] - 42s 242ms/step - loss: 4740.6123 - accuracy: 0.3332 - val_loss: 2657.3357 - val_accuracy: 0.3653\n",
            "Epoch 18/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 4178.2129 - accuracy: 0.3203\n",
            "CALLBACK time  2275.133107633 \n",
            "\n",
            "174/174 [==============================] - 43s 246ms/step - loss: 4178.2129 - accuracy: 0.3203 - val_loss: 2653.8035 - val_accuracy: 0.3608\n",
            "Epoch 19/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3709.6873 - accuracy: 0.3257\n",
            "CALLBACK time  2318.424032017 \n",
            "\n",
            "174/174 [==============================] - 43s 248ms/step - loss: 3709.6873 - accuracy: 0.3257 - val_loss: 2616.4995 - val_accuracy: 0.3341\n",
            "Epoch 20/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3543.3887 - accuracy: 0.3213\n",
            "CALLBACK time  2359.748174243 \n",
            "\n",
            "174/174 [==============================] - 41s 237ms/step - loss: 3543.3887 - accuracy: 0.3213 - val_loss: 2557.8450 - val_accuracy: 0.3408\n",
            "Epoch 21/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3408.6812 - accuracy: 0.3087\n",
            "CALLBACK time  2441.713416363 \n",
            "\n",
            "174/174 [==============================] - 41s 238ms/step - loss: 3408.6812 - accuracy: 0.3087 - val_loss: 2558.5481 - val_accuracy: 0.3318\n",
            "Epoch 22/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3050.6235 - accuracy: 0.2634\n",
            "CALLBACK time  2482.956100293 \n",
            "\n",
            "174/174 [==============================] - 41s 235ms/step - loss: 3050.6235 - accuracy: 0.2634 - val_loss: 2564.6157 - val_accuracy: 0.3274\n",
            "Epoch 23/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3125.4578 - accuracy: 0.2407\n",
            "CALLBACK time  2524.296724421 \n",
            "\n",
            "174/174 [==============================] - 41s 237ms/step - loss: 3125.4578 - accuracy: 0.2407 - val_loss: 2546.1450 - val_accuracy: 0.3363\n",
            "Epoch 24/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2879.3994 - accuracy: 0.2350\n",
            "CALLBACK time  2566.113035319 \n",
            "\n",
            "174/174 [==============================] - 42s 241ms/step - loss: 2879.3994 - accuracy: 0.2350 - val_loss: 2533.3335 - val_accuracy: 0.3363\n",
            "Epoch 25/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 3061.5544 - accuracy: 0.2112\n",
            "CALLBACK time  2647.63751984 \n",
            "\n",
            "174/174 [==============================] - 41s 238ms/step - loss: 3061.5544 - accuracy: 0.2112 - val_loss: 2612.4365 - val_accuracy: 0.3296\n",
            "Epoch 26/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2799.7856 - accuracy: 0.2109\n",
            "CALLBACK time  2690.010761871 \n",
            "\n",
            "174/174 [==============================] - 42s 244ms/step - loss: 2799.7856 - accuracy: 0.2109 - val_loss: 2528.1116 - val_accuracy: 0.3318\n",
            "Epoch 27/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2749.1069 - accuracy: 0.1943\n",
            "CALLBACK time  2770.895762372 \n",
            "\n",
            "174/174 [==============================] - 41s 238ms/step - loss: 2749.1069 - accuracy: 0.1943 - val_loss: 2530.1235 - val_accuracy: 0.3318\n",
            "Epoch 28/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2826.7131 - accuracy: 0.1889\n",
            "CALLBACK time  2812.716197062 \n",
            "\n",
            "174/174 [==============================] - 42s 240ms/step - loss: 2826.7131 - accuracy: 0.1889 - val_loss: 2536.9365 - val_accuracy: 0.3318\n",
            "Epoch 29/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2785.3477 - accuracy: 0.1666\n",
            "CALLBACK time  2853.91391462 \n",
            "\n",
            "174/174 [==============================] - 41s 237ms/step - loss: 2785.3477 - accuracy: 0.1666 - val_loss: 2545.2737 - val_accuracy: 0.3318\n",
            "Epoch 30/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2686.1433 - accuracy: 0.1544\n",
            "CALLBACK time  2935.290519265 \n",
            "\n",
            "174/174 [==============================] - 41s 234ms/step - loss: 2686.1433 - accuracy: 0.1544 - val_loss: 2526.4314 - val_accuracy: 0.3318\n",
            "Epoch 31/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2681.0913 - accuracy: 0.1522\n",
            "CALLBACK time  2976.373468173 \n",
            "\n",
            "174/174 [==============================] - 41s 235ms/step - loss: 2681.0913 - accuracy: 0.1522 - val_loss: 2525.9543 - val_accuracy: 0.3318\n",
            "Epoch 32/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2692.8081 - accuracy: 0.1608\n",
            "CALLBACK time  3016.99172935 \n",
            "\n",
            "174/174 [==============================] - 40s 233ms/step - loss: 2692.8081 - accuracy: 0.1608 - val_loss: 2525.4507 - val_accuracy: 0.3318\n",
            "Epoch 33/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2667.9160 - accuracy: 0.1583\n",
            "CALLBACK time  3058.864544776 \n",
            "\n",
            "174/174 [==============================] - 42s 241ms/step - loss: 2667.9160 - accuracy: 0.1583 - val_loss: 2524.9155 - val_accuracy: 0.3318\n",
            "Epoch 34/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2672.1533 - accuracy: 0.1468\n",
            "CALLBACK time  3099.067679895 \n",
            "\n",
            "174/174 [==============================] - 40s 230ms/step - loss: 2672.1533 - accuracy: 0.1468 - val_loss: 2524.3516 - val_accuracy: 0.3318\n",
            "Epoch 35/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2640.4397 - accuracy: 0.1465\n",
            "CALLBACK time  3139.503736613 \n",
            "\n",
            "174/174 [==============================] - 41s 232ms/step - loss: 2640.4397 - accuracy: 0.1465 - val_loss: 2524.2283 - val_accuracy: 0.3318\n",
            "Epoch 36/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2597.2607 - accuracy: 0.1425\n",
            "CALLBACK time  3180.446592084 \n",
            "\n",
            "174/174 [==============================] - 41s 235ms/step - loss: 2597.2607 - accuracy: 0.1425 - val_loss: 2523.1189 - val_accuracy: 0.3318\n",
            "Epoch 37/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2733.6184 - accuracy: 0.1475\n",
            "CALLBACK time  3221.255734765 \n",
            "\n",
            "174/174 [==============================] - 41s 234ms/step - loss: 2733.6184 - accuracy: 0.1475 - val_loss: 2522.4490 - val_accuracy: 0.3318\n",
            "Epoch 38/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2609.6516 - accuracy: 0.1501\n",
            "CALLBACK time  3261.758612236 \n",
            "\n",
            "174/174 [==============================] - 40s 232ms/step - loss: 2609.6516 - accuracy: 0.1501 - val_loss: 2521.7368 - val_accuracy: 0.3341\n",
            "Epoch 39/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2611.8896 - accuracy: 0.1472\n",
            "CALLBACK time  3302.220760859 \n",
            "\n",
            "174/174 [==============================] - 40s 233ms/step - loss: 2611.8896 - accuracy: 0.1472 - val_loss: 2520.9810 - val_accuracy: 0.3341\n",
            "Epoch 40/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2664.6553 - accuracy: 0.1457\n",
            "CALLBACK time  3343.452833325 \n",
            "\n",
            "174/174 [==============================] - 41s 234ms/step - loss: 2664.6553 - accuracy: 0.1457 - val_loss: 2520.1826 - val_accuracy: 0.3341\n",
            "Epoch 41/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2553.9648 - accuracy: 0.1414\n",
            "CALLBACK time  3384.300964535 \n",
            "\n",
            "174/174 [==============================] - 41s 235ms/step - loss: 2553.9648 - accuracy: 0.1414 - val_loss: 2519.3320 - val_accuracy: 0.3318\n",
            "Epoch 42/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2640.9304 - accuracy: 0.1375\n",
            "CALLBACK time  3425.859947188 \n",
            "\n",
            "174/174 [==============================] - 41s 238ms/step - loss: 2640.9304 - accuracy: 0.1375 - val_loss: 2518.4299 - val_accuracy: 0.3341\n",
            "Epoch 43/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2610.2395 - accuracy: 0.1385\n",
            "CALLBACK time  3507.668259147 \n",
            "\n",
            "174/174 [==============================] - 41s 238ms/step - loss: 2610.2395 - accuracy: 0.1385 - val_loss: 2517.4758 - val_accuracy: 0.3341\n",
            "Epoch 44/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2621.4343 - accuracy: 0.1306\n",
            "CALLBACK time  3548.318688889 \n",
            "\n",
            "174/174 [==============================] - 41s 234ms/step - loss: 2621.4343 - accuracy: 0.1306 - val_loss: 2516.4639 - val_accuracy: 0.3318\n",
            "Epoch 45/50\n",
            "174/174 [==============================] - ETA: 0s - loss: 2590.2063 - accuracy: 0.1295\n",
            "CALLBACK time  3589.119154288 \n",
            "\n",
            "174/174 [==============================] - 40s 233ms/step - loss: 2590.2063 - accuracy: 0.1295 - val_loss: 2515.3926 - val_accuracy: 0.3341\n",
            "Epoch 46/50\n",
            " 67/174 [==========>...................] - ETA: 22s - loss: 2587.0278 - accuracy: 0.1297"
          ]
        }
      ],
      "source": [
        "#MAIN TRAINNING SCRIPT\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import time\n",
        "\n",
        "stop_flag = False\n",
        "#MARK START TIME\n",
        "start = timer()\n",
        "\n",
        "#Initialize only for first run\n",
        "epochs = 50\n",
        "epochs_done = 0\n",
        "current_arch = 0\n",
        "current_model = None\n",
        "\n",
        "#IF CONTINUING LOAD STATE\n",
        "if os.path.exists('state.state'):\n",
        "  print('\\nINIT MODEL FROM SAVED STATE \\n')\n",
        "  current_model, epochs_done, current_arch = load_state()\n",
        "  print(current_model.loss)\n",
        "  print(current_model.optimizer)\n",
        "  print(current_model.metrics_names)\n",
        "  print(current_model.metrics)\n",
        "#ELSE CREATE A MODEL  \n",
        "else:\n",
        "  print('\\nCREATING MODEL\\n')\n",
        "#HYPERPARAMS FOR THIS RUN\n",
        "  model_params = models[current_arch]\n",
        "  kernel_num = model_params['kernel_num']\n",
        "  kernel_size = model_params['kernel_size']\n",
        "  fc_size = model_params['fc_size']\n",
        "  conv_num = model_params['conv_layer']\n",
        "  current_model = create_model(ker_num=kernel_num,ker_size=kernel_size,fc_size=fc_size,conv_layer_num=conv_num)\n",
        "  print(current_model.summary())  \n",
        "\n",
        "train_generator, val_generator, test_generator = get_datasets() \n",
        "print(train_generator.class_indices)\n",
        "print(val_generator.class_indices)\n",
        "print(test_generator.class_indices)\n",
        "\n",
        "#EARLY STOP CALLBACK\n",
        "callbackES = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10,restore_best_weights=True)\n",
        "\n",
        "#CALL BACK FOR SAVING AT 5 HOURS\n",
        "stop_cb = newcb(start=start)\n",
        "\n",
        "#ITERATE THROUGH CANDIDATE MODELS\n",
        "for arch in range(current_arch,len(models)):\n",
        "  current_arch = arch\n",
        "  print('RUNNING MODEL ',current_arch)\n",
        "  if stop_flag == True:\n",
        "    print('BREAKING FROM LOOP BECAUSE CALLBACK STOPPED TRAINNNG')\n",
        "    break\n",
        "#ITEREATE THROUGH EPOCHS  \n",
        "  history=current_model.fit(train_generator,validation_data = val_generator,epochs = epochs-epochs_done,class_weight=weights_per_class,verbose = 1,shuffle = True,callbacks=[stop_cb,callbackES])\n",
        "\n",
        "  fig, ax = plt.subplots(2)\n",
        "\n",
        "  ax[0].set_ylabel('Loss')\n",
        "  ax[1].set_ylabel('Accuracy')\n",
        "\n",
        "  ax[0].plot(history.history['loss'], color='red') \n",
        "  ax[0].plot(history.history['val_loss'], color='blue') \n",
        "\n",
        "  ax[1].plot(history.history['accuracy'], color='red') \n",
        "  ax[1].plot(history.history['val_accuracy'], color='blue') \n",
        "\n",
        "  filename2 = 'train_history'+str(arch)+'.png'\n",
        "  fig.savefig(filename2)\n",
        "  plt.show()\n",
        "\n",
        "  print(stop_flag,' AFTER FIT FLAG IS')\n",
        "  file_name = 'model_' + str(arch) + '.model'\n",
        "  \n",
        "  if stop_flag == False:\n",
        "   \n",
        "   with open(file_name, 'wb') as cfg:\n",
        "      pickle.dump(current_model,cfg)\n",
        "\n",
        "   model_params = models[current_arch+1]\n",
        "   kernel_num = model_params['kernel_num']\n",
        "   kernel_size = model_params['kernel_size']\n",
        "   fc_size = model_params['fc_size']\n",
        "   conv_num = model_params['conv_layer']\n",
        "   current_model = create_model(ker_num=kernel_num,ker_size=kernel_size,fc_size=fc_size,conv_layer_num=conv_num)\n",
        "   print(current_model.summary())  \n",
        "   epochs_done = 0   \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Experiment_ds1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}